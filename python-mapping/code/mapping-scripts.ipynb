{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b88778-052d-46dc-886c-cc15a240b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c10fd-584b-4006-a8c6-4dd291729787",
   "metadata": {},
   "source": [
    "I love using Jupyter notebooks for GIS analysis (all analysis really) because I can integrate my notes right in with my code. That way, any issues, data aberations, findings or general notes that I have will always be right there with my code. Very helpful for reproducability and collaboration.\n",
    "\n",
    "I also love that I can run different bits of code independently. When you have large datasets or files that you're reading in with code, being able to read the data into memory and test various aspects of your code will save you HUNDREDS of hours. Seriously. \n",
    "\n",
    "HOWEVER, the ability to run different bits of code at different times makes for a dangerous situation if you're not careful with your variable names and the sequence that you run your code. In other words... you can rename variables accidentally and forget which dataset the variable pertains to AND you can run blocks out of order and get weird results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422a67f1-0133-4f6a-86d1-c32d259522dd",
   "metadata": {},
   "source": [
    "### Adding geospatial data using geopandas\n",
    "You can use geopandas to pull in zipped shapefiles! Geopandas dataframes are pretty much the same as pandas dataframes so you can do pretty much all of the same commands AND MORE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d67c4-a48e-4217-acf2-b9771f79a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "nash_redlining = gpd.read_file('../GIS/redlining/TNNashville19XX.zip')\n",
    "nash_redlining.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee87f0-f0f9-422f-aec3-dac3ccbebb10",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Checkout CRS details\n",
    "Super easy and convenient way to see which projection your shapefile is using and what the units are if you're trying to do buffers or proximity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9899d03-882c-42f0-8c73-a9eb71e1c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nash_redlining.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b413349-ebbc-4a0f-9302-54eaea8be0c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Change the CRS\n",
    "The \"Area of Use\" readout is so very useful here. I found this projection [by going here](https://epsg.io/?q=tennessee%20kind%3APROJCRS) FYI. I renamed my variable here but really you can just do this inplace if you're not going to need the unprojected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f120da-98d6-4545-92da-93acc1a554be",
   "metadata": {},
   "outputs": [],
   "source": [
    "nash_redlining_2274 = nash_redlining.to_crs('EPSG:2274')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304698d4-df8f-4c5e-9598-f31bcf17a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nash_redlining_2274.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a282c-c7de-4199-9a77-5b029ddcc5b5",
   "metadata": {},
   "source": [
    "### Pulling data with Census API\n",
    "Raise your hand if you hate going to data.census.gov. Me too. This script allows you to pull only the fields you need without downloading a bunch of crap you don't. Here are the steps to using this:\n",
    "\n",
    "**1. Get an API key [here](https://api.census.gov/data/key_signup.html)**\n",
    "\n",
    "**2. Decide [which survey](https://www.census.gov/data/developers/data-sets.html) you need (decennial, ACS, etc)**\n",
    "\n",
    "**3. Figure out which variables, geographies and years you want to pull data for**\n",
    "Using [the link above](https://www.census.gov/data/developers/data-sets.html), follow the survey dropdowns to find the survey API page. For example, if we wanted the ACS 1-year data we'd go here to learn what geographies and variables are available for it: https://www.census.gov/data/developers/data-sets/acs-1year.html. Here we learn more about the subsets of this dataset (for instance the ACS 1-year has detail tables, subject tables, data tables and comparison tables). Once we know which subset we want, scroll down to find [examples](https://api.census.gov/data/2021/acs/acs1/profile/examples.html), links to variable lists and available geographies for each subset.\n",
    "\n",
    "**4. Construct your URL**\n",
    "I like to put all of the variables I want to pull into a list and then turn that list into a string and feed it into the URL that will fetch the data for us.\n",
    "\n",
    "```\n",
    "FYI, 1-year data are usually only available for larger areas due to sampling size issues. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bca16c-521a-4374-a6d2-735d33e6c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DP05_0033E = Estimate!!RACE!!Total population\n",
    "#DP05_0034E = Estimate!!RACE!!Total population!!One race\n",
    "#DP05_0037E = Estimate!!RACE!!Total population!!One race!!White\n",
    "#DP05_0038E = Estimate!!RACE!!Total population!!One race!!Black or African American\n",
    "#DP05_0039E = Estimate!!RACE!!Total population!!One race!!American Indian and Alaska Native\n",
    "#DP05_0044E = Estimate!!RACE!!Total population!!One race!!Asian\n",
    "#DP05_0052E = Estimate!!RACE!!Total population!!One race!!Native Hawaiian and Other Pacific Islander\n",
    "\n",
    "#OR the non-single race data\n",
    "\n",
    "#DP05_0063E = Estimate!!Race alone or in combination with one or more other races!!Total population\n",
    "#DP05_0064E = Estimate!!Race alone or in combination with one or more other races!!Total population!!White\n",
    "#DP05_0065E = Estimate!!Race alone or in combination with one or more other races!!Total population!!Black or African American\n",
    "#DP05_0066E = Estimate!!Race alone or in combination with one or more other races!!Total population!!American Indian and Alaska Native\n",
    "#DP05_0067E = Estimate!!Race alone or in combination with one or more other races!!Total population!!Asian\n",
    "#DP05_0068E = Estimate!!Race alone or in combination with one or more other races!!Total population!!Native Hawaiian and Other Pacific Islander\n",
    "\n",
    "MYKEY = '5f5e920f59df757178d859ae70a4cb8297cb739c'\n",
    "\n",
    "var_list = ['GEO_ID','NAME','DP05_0033E','DP05_0034E','DP05_0037E','DP05_0038E','DP05_0039E','DP05_0044E','DP05_0052E']\n",
    "var_str = ','.join(var_list)\n",
    "\n",
    "#I like to rename my data columns cause I'll get lost otherwise!\n",
    "rename_cols = {'DP05_0033E':'pop',\n",
    "               'DP05_0034E':'pop_1r',\n",
    "               'DP05_0037E':'pop_1r_white',\n",
    "               'DP05_0038E':'pop_1r_black',\n",
    "               'DP05_0039E':'pop_1r_aian',\n",
    "               'DP05_0044E':'pop_1r_asian',\n",
    "               'DP05_0052E':'pop_1r_nhpi',\n",
    "              }\n",
    "\n",
    "year = 2021\n",
    "\n",
    "data_url = 'https://api.census.gov/data/'+str(year)+'/acs/acs5/profile?get='+var_str+'&for=tract:*&in=state:47&key='+MYKEY\n",
    "demo_tract_df = pd.read_json(data_url)\n",
    "new_header = demo_tract_df.iloc[0] #grab the first row for the header\n",
    "demo_tract_df = demo_tract_df[1:] #take the data less the header row\n",
    "demo_tract_df.columns = new_header #set the header row as the df header\n",
    "demo_tract_df.rename(columns=rename_cols, inplace=True) #heres where we actually rename\n",
    "demo_tract_df['year'] = year\n",
    "\n",
    "print(len(demo_tract_df))\n",
    "display(demo_tract_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176d117e-e8c1-4a1e-8190-a4724ea77360",
   "metadata": {},
   "source": [
    "But because this is NICAR and the internets are likely super slow, here's that exact data but as a local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9394017-da94-417f-b0cb-0459ab4764db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo_tract_df = pd.read_csv('../data/acs5-2021-demo-47-tracts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d1abe-4310-4453-9d32-93d9bbbd2404",
   "metadata": {},
   "source": [
    "### You can pull multiple years really easily with code too!\n",
    "Just be careful not to compare overlapping years of data when you're using multi-year surveys like the ACS 5-year!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a194175-3ed7-4114-9a04-85810585676f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MYKEY = 'xxxxxxxxxxxxxxxxxxxx'\n",
    "\n",
    "var_list = ['GEO_ID','NAME','DP05_0033E','DP05_0034E','DP05_0037E','DP05_0038E','DP05_0039E','DP05_0044E','DP05_0052E']\n",
    "var_str = ','.join(var_list)\n",
    "\n",
    "#I like to rename my data columns cause I'll get lost otherwise!\n",
    "rename_cols = {'DP05_0033E':'pop',\n",
    "               'DP05_0034E':'pop_1r',\n",
    "               'DP05_0037E':'pop_1r_white',\n",
    "               'DP05_0038E':'pop_1r_black',\n",
    "               'DP05_0039E':'pop_1r_aian',\n",
    "               'DP05_0044E':'pop_1r_asian',\n",
    "               'DP05_0052E':'pop_1r_nhpi',\n",
    "              }\n",
    "\n",
    "year_list = [2016,2021] #the closest datasets that don't overlap reference periods\n",
    "\n",
    "df_list = [] #this will hold each years data till we're ready to put them all together\n",
    "for year in year_list:\n",
    "    data_url = 'https://api.census.gov/data/'+str(year)+'/acs/acs5/profile?get='+var_str+'&for=tract:*&in=state:47&key='+MYKEY\n",
    "    df = pd.read_json(data_url)\n",
    "    new_header = df.iloc[0] #grab the first row for the header\n",
    "    df = df[1:] #take the data less the header row\n",
    "    df.columns = new_header #set the header row as the df header\n",
    "    df['year'] = year\n",
    "    display(df.head())\n",
    "    df_list.append(df)\n",
    "    \n",
    "    \n",
    "demo_tract_df = pd.concat(df_list, axis=0, ignore_index=True) #putting them all together!\n",
    "demo_tract_df.rename(columns=rename_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d5a4d-cced-4f2a-9b90-3def6839bbbc",
   "metadata": {},
   "source": [
    "### Puling tigerline files with code\n",
    "Find the shapes you're after here: https://www2.census.gov/geo/tiger/TIGER2022/. Copy the link to the zip file. In a lot of cases the shapefiles are broken out by state. Familiarize yourself with the state FIPS codes. \n",
    "\n",
    "- PLACE = cities, towns, etc\n",
    "- SCSD and UNSD = school districts\n",
    "- TABBLOCK20 = Census blocks\n",
    "- BG = Census block group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0512173-c9b7-4ccb-afd9-ae3f669d6ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tracts_shp = gpd.read_file('https://www2.census.gov/geo/tiger/TIGER2022/TRACT/tl_2022_47_tract.zip')\n",
    "tracts_shp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5625a90-9bf6-4d85-ad67-e525808ad72d",
   "metadata": {},
   "source": [
    "### Joining data to shapes (aka attribute merge)\n",
    "Joining data to shapes is so easy. First we look to see what our common field is between the two datasets. And just to be sure the field type is the same, we'll print the `dtypes` or data types of the field we wanna join on.\n",
    "\n",
    "FYI, sometimes with fields type `object` some of the values are strings and some are numbers. LAME. We'll just make them all into string!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc009ae-114a-41cb-b41c-2db8e068029f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tracts_shp = gpd.read_file('../GIS/tl_2022_47_tract.zip', dtype={'TRACTCE':str})\n",
    "display(tracts_shp.head(1))\n",
    "print(tracts_shp.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d870c0c-5bad-41ff-b357-af4ed00d3786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo_tract_df = pd.read_csv('../data/acs5-2021-demo-47-tracts.csv', dtype={'tract':str})\n",
    "display(demo_tract_df.head(1))\n",
    "print(demo_tract_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abbcff1-0baa-4359-bd80-77fa68662770",
   "metadata": {},
   "source": [
    "And here's where we do our attribute merge! Here's more info on geopandas merges: https://geopandas.org/en/stable/docs/user_guide/mergingdata.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0732c79-451e-4148-a0cd-3a3dbef5cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_tract_shp_df = tracts_shp.merge(demo_tract_df,left_on='TRACTCE',right_on='tract',how='left')\n",
    "display(demo_tract_shp_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af9cee-ac9f-4395-a8e0-a1cfb0cc2b01",
   "metadata": {},
   "source": [
    "I always like to make sure my original dataframe and my resulting dataframe are the same length. Otherwise, maybe I did something wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034b240-b5bc-48c9-a105-1ecb4a3b9122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(tracts_shp))\n",
    "print(len(demo_tract_shp_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78826ed1-41c5-447a-bdd9-bcd965503fcc",
   "metadata": {},
   "source": [
    "I also like to check and see if any records didn't merge. Maybe the two datasets didn't contain the same records or maybe something is off with the data. Good to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb8306-902e-4226-bca7-25a1a97ada1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_data = demo_tract_shp_df.loc[demo_tract_shp_df['pop'].isna()]\n",
    "print(len(no_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6bbcd7-f0e0-4f51-aea3-07ba5ab2b3d6",
   "metadata": {},
   "source": [
    "### Create geo data from csv with latitude/longitude\n",
    "This is going to be useful for when we want to do spatial joins on points and polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa843f88-c74c-47c9-b92f-469d2436b4f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Traffic_Accidents.csv')\n",
    "accidents_shp = gpd.GeoDataFrame(df, geometry=gpd.GeoSeries.from_xy(df['Longitude'], df['Latitude']), crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c280c-5958-4d92-ad0a-b8f11edbc4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accidents_shp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd5974-786a-41ff-936d-f6f1ebb2636b",
   "metadata": {},
   "source": [
    "### Spatial join between points and polygon\n",
    "Which Nashville neighborhood has the most car accidents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6960a76-abcf-4225-928c-0ebe9e3b2ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hoods = gpd.read_file('../GIS/Neighborhood Association Boundaries (GIS).zip')\n",
    "\n",
    "accidents_hoods = accidents_shp.sjoin(hoods, how='left', predicate='intersects')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ea074-9a24-4759-a27e-dfee812e3863",
   "metadata": {},
   "source": [
    "Whoops! Our geo dataframes don't have the same CRS! But we learned how to change that earlier didn't we! Let's use what we learned. For this task it doesn't matter if our geo dataframes are in a geographic CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a14733a-97a7-4f0b-9990-a21e507ad075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(hoods.crs)\n",
    "print('')\n",
    "display(accidents_shp.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a3a405-e0d6-4b7d-a904-ee9c70ff52e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hoods = hoods.to_crs('EPSG:4326')\n",
    "accidents_hoods = accidents_shp.sjoin(hoods, how='left', predicate='intersects')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6872b9-eeb9-4b90-90ae-749db826e177",
   "metadata": {},
   "source": [
    "Nashville is one of those cities that doesn't seem to have real neighborhoods as defined and tracked by the city. They have neighborhood associates which kinda suck because they don't cover the whole city. So let's just grab the accidents that happen in the neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1cf2e5-1a1d-4a40-bd5f-19e9b5fe712d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with_hood = accidents_hoods.loc[~(accidents_hoods['name'].isna())]\n",
    "\n",
    "print(len(accidents_hoods))\n",
    "print(len(with_hood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c998cf7-8518-4434-9c47-61332a279337",
   "metadata": {},
   "source": [
    "And now, which neighborhoods have the most accidents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c4cbe9-3d90-412a-ae5b-ef4f073e9445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accidents_by_hood = with_hood.groupby('name').size().reset_index().sort_values(0, ascending=False)\n",
    "accidents_by_hood.rename(columns={0:'accident_cnt'},inplace=True) #just renaming our count field \n",
    "\n",
    "display(accidents_by_hood.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a990e398-9c30-443f-900f-e52094549ee9",
   "metadata": {},
   "source": [
    "### Using plot.ly for interactive analysis\n",
    "All of this scripted analysis is good and all but... what use is it if we can't see what's going on. We're working with geographic data which is inherently visual. Let's get some displays up here. \n",
    "\n",
    "We're using the basic choropleth map here, but there's also a [Mapbox version](https://plotly.com/python/mapbox-county-choropleth/) that will give you better basemaps. You'll need a Mapbox account and an API key for that though so we're not going to touch on it here.\n",
    "\n",
    "Additionally, there are [all sorts of maps we can make](https://plotly.com/python/maps/), not just choropleth! Plot.ly also does bar charts, scatter plots and many many other types of charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d8df39-801a-4075-b8c6-d079a246be13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#we run this separately because if we try and run it more than once we'll get an error saying that there's no\n",
    "#\"name\" column in our hoods dataset. That's cause we've made it the index with this script and it stops being\n",
    "#recognized as a column when it's the index\n",
    "hoods.set_index('name',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf66f46c-8356-40fa-a00a-fb3cb39a9dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#now we can run this any number of times and change the parameters, like which field the color\n",
    "#represents, what color scale we're using, etc.\n",
    "fig = px.choropleth(accidents_by_hood, geojson=hoods, locations='name', color='accident_cnt',\n",
    "                           color_continuous_scale='Reds',\n",
    "                           range_color=(0, 2210),\n",
    "                           scope=\"usa\",\n",
    "                           labels={'accident_cnt':'accidents'}\n",
    "                          )\n",
    "fig.update_geos(fitbounds=\"locations\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69962295-d43f-47c6-a0ac-e6a407ec3aa3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simplifying polygon data for Datawrapper/Flourish display\n",
    "Plot.ly is great for visualizing in this notebook, and even sharing with coworkers who can also read and run your code, but sometimes we need to share with non-technical people and/or get this data into a map that we can embed within a story. I like Datawrapper and Flourish for that.\n",
    "\n",
    "But interactive displays are greatly improved by serving readers smaller file sizes.\n",
    "\n",
    "I've messed around with simplifying shapes using python... but honestly I haven't found a super intuitive, quality method. My suggestion... export your shapes as a geojon and toss into [mapshaper](https://mapshaper.org/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ad7c9-3661-4015-a745-943eec0134b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapbox and other services like the projection to be in this CRS\n",
    "accidents_by_hood.to_crs('EPSG:4326').to_file('../GIS/analyzed/nash-accidents-hoods.geojson', driver='GeoJSON')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad2b3a-fca8-42dc-ae38-714be7b244fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Intersections!\n",
    "Sometimes we need to fit data to shapes for which data aren't available. What if we wanted to get the current demographic makeup of Nashville's historic redlining districts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c46d78-1e96-4f66-a2f9-bdb4b3c41c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#first we import the data. They dtype thing is just to make sure our join column is of the right type\n",
    "tracts_shp = gpd.read_file('../GIS/tl_2022_47_tract.zip', dtype={'TRACTCE':str})\n",
    "nash_redline = gpd.read_file('../GIS/redlining/TNNashville19XX.zip')\n",
    "\n",
    "\n",
    "#our shapes need to be in the same projection for this\n",
    "tracts_shp.to_crs('EPSG:2274',inplace=True)\n",
    "nash_redline.to_crs('EPSG:2274',inplace=True)\n",
    "\n",
    "\n",
    "#we'll want to join demographic data to our tracts shape now\n",
    "demo_tract_df = pd.read_csv('../data/acs5-2021-demo-47-tracts.csv', dtype={'tract':str})\n",
    "demo_tract_shp_df = tracts_shp.merge(demo_tract_df,left_on='TRACTCE',right_on='tract',how='left')\n",
    "\n",
    "\n",
    "#and we'll need to calculate the area of the tracts before and after we do the intersection so we can\n",
    "#calculate the actual estimated count of people of different races in each tract segmemt.\n",
    "#we're multiplying by 3.587E-8 to turn unmanagably large feet into manageable miles!\n",
    "demo_tract_shp_df['pre_area'] = demo_tract_shp_df['geometry'].area * 3.587E-8\n",
    "\n",
    "\n",
    "#now let's do that intersection!\n",
    "tracts_redlining = gpd.overlay(demo_tract_shp_df, nash_redline, how='intersection')\n",
    "\n",
    "\n",
    "#and calculate the area post intersection.  \n",
    "tracts_redlining['post_area'] = tracts_redlining['geometry'].area * 3.587E-8\n",
    "\n",
    "\n",
    "#from the pre and post area calculations we create a percentage\n",
    "tracts_redlining['pct_area'] = tracts_redlining['post_area']/demo_tract_shp_df['pre_area']\n",
    "\n",
    "#and then we multiply our tract population counts by that percentage\n",
    "#to get an estimated count of people who live in the segments of the tract\n",
    "#that fall within each redlining district\n",
    "tracts_redlining['post_pop'] = tracts_redlining['pop'] * tracts_redlining['pct_area']\n",
    "tracts_redlining['post_pop1r'] = tracts_redlining['pop_1r'] * tracts_redlining['pct_area']\n",
    "tracts_redlining['post_white'] = tracts_redlining['pop_1r_white'] * tracts_redlining['pct_area']\n",
    "tracts_redlining['post_black'] = tracts_redlining['pop_1r_black'] * tracts_redlining['pct_area']\n",
    "tracts_redlining['post_aian'] = tracts_redlining['pop_1r_aian'] * tracts_redlining['pct_area']\n",
    "tracts_redlining['post_asian'] = tracts_redlining['pop_1r_asian'] * tracts_redlining['pct_area']\n",
    "tracts_redlining['post_nhpi'] = tracts_redlining['pop_1r_nhpi'] * tracts_redlining['pct_area']\n",
    "\n",
    "#and for display purposes, let's calculate one more value... post_pct_poc\n",
    "tracts_redlining['post_pct_poc'] = (tracts_redlining['post_pop1r'] - tracts_redlining['post_white'])/tracts_redlining['post_pop1r']\n",
    "\n",
    "\n",
    "#and output as a file so we can checkout in QGIS!\n",
    "tracts_redlining.to_file('../GIS/analyzed/nashville-redlining-tracts-int.shp')\n",
    "\n",
    "tracts_redlining.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63767d7-d1c2-412d-b3ac-42864d2899f4",
   "metadata": {},
   "source": [
    "This is another place where I'm going to admit that I like using manual tools better than using code. At this point, let's bring all three of our shapes in to QGIS to see what we just did!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4a3585-04f4-4367-b36a-812e36324e2c",
   "metadata": {},
   "source": [
    "### Possible things to explore\n",
    "- Which neighborhoods have the most hit and run accidents?\n",
    "- What are the current demographics of Nashville's historic redlining districts?\n",
    "- Which neighborhoods have the most on-site beer serving establishments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee5943-58b8-4a36-a929-4abcd027d290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
